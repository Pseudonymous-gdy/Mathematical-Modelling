{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1bba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5098, 20)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score\n",
    "\n",
    "# =========================\n",
    "# 1. 读数据\n",
    "# =========================\n",
    "try:\n",
    "    df = pd.read_csv(\"2024_Wimbledon_featured_matches.csv\")\n",
    "except:\n",
    "    df = pd.read_csv(\"Wimbledon_featured_matches.csv\")\n",
    "\n",
    "# =========================\n",
    "# 2. 目标变量\n",
    "# =========================\n",
    "# 假设 point_victor: 1 = P1 赢分, 2 = P2 赢分\n",
    "df = df[df[\"point_victor\"].isin([1, 2])]\n",
    "df[\"y\"] = (df[\"point_victor\"] == 1).astype(int)\n",
    "\n",
    "# =========================\n",
    "# 3. 构造\"无记忆\"特征\n",
    "# =========================\n",
    "# 构造缺失的特征\n",
    "df[\"is_break_point\"] = ((df[\"p1_break_pt\"] > 0) | (df[\"p2_break_pt\"] > 0)).astype(int)\n",
    "df[\"is_tiebreak\"] = ((df[\"p1_score\"] == \"15\") & (df[\"p2_score\"] == \"15\")).astype(int)  # 简化版\n",
    "df[\"is_deuce\"] = ((df[\"p1_score\"] == \"D\") | (df[\"p2_score\"] == \"D\")).astype(int)\n",
    "\n",
    "# 计算上一分的持续时间\n",
    "df[\"elapsed_seconds\"] = pd.to_timedelta(df[\"elapsed_time\"]).dt.total_seconds()\n",
    "df[\"point_duration\"] = df.groupby(\"match_id\")[\"elapsed_seconds\"].diff()\n",
    "df[\"prev_point_duration\"] = df.groupby(\"match_id\")[\"point_duration\"].shift(1)\n",
    "\n",
    "# 编码分类变量\n",
    "le_serve_width = LabelEncoder()\n",
    "le_serve_depth = LabelEncoder()\n",
    "le_return_depth = LabelEncoder()\n",
    "\n",
    "df[\"serve_width_encoded\"] = le_serve_width.fit_transform(df[\"serve_width\"].astype(str))\n",
    "df[\"serve_depth_encoded\"] = le_serve_depth.fit_transform(df[\"serve_depth\"].astype(str))\n",
    "df[\"return_depth_encoded\"] = le_return_depth.fit_transform(df[\"return_depth\"].astype(str))\n",
    "\n",
    "# 获取上一分的特征值（t-1）\n",
    "df[\"prev_p1_distance_run\"] = df.groupby(\"match_id\")[\"p1_distance_run\"].shift(1)\n",
    "df[\"prev_p2_distance_run\"] = df.groupby(\"match_id\")[\"p2_distance_run\"].shift(1)\n",
    "df[\"prev_rally_count\"] = df.groupby(\"match_id\")[\"rally_count\"].shift(1)\n",
    "df[\"prev_speed_mph\"] = df.groupby(\"match_id\")[\"speed_mph\"].shift(1)\n",
    "df[\"prev_serve_width_encoded\"] = df.groupby(\"match_id\")[\"serve_width_encoded\"].shift(1)\n",
    "df[\"prev_serve_depth_encoded\"] = df.groupby(\"match_id\")[\"serve_depth_encoded\"].shift(1)\n",
    "df[\"prev_return_depth_encoded\"] = df.groupby(\"match_id\")[\"return_depth_encoded\"].shift(1)\n",
    "\n",
    "feature_cols = [\n",
    "    # 发球\n",
    "    \"server\",\n",
    "    \"serve_no\",\n",
    "\n",
    "    # 比分 / 阶段\n",
    "    \"set_no\",\n",
    "    \"game_no\",\n",
    "    \"point_no\",\n",
    "    \"p1_games\",\n",
    "    \"p2_games\",\n",
    "    \"p1_sets\",\n",
    "    \"p2_sets\",\n",
    "\n",
    "    # 关键分\n",
    "    \"is_break_point\",\n",
    "    \"is_tiebreak\",\n",
    "    \"is_deuce\",\n",
    "    \n",
    "    # 上一分的持续时间\n",
    "    \"prev_point_duration\",\n",
    "    \n",
    "    # 上一分的特征（t-1）\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"y\"].values\n",
    "\n",
    "# 缺失值简单处理（baseline）\n",
    "X = X.fillna(0)\n",
    "\n",
    "# =========================\n",
    "# 4. 训练 / 测试切分\n",
    "#    （注意：这里是\"非时序 baseline\"，\n",
    "#     所以允许随机切分）\n",
    "# =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa52a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss : 0.6431823512421097\n",
      "Brier    : 0.22105746000330692\n",
      "ROC AUC  : 0.6821928227793279\n",
      "                      feature      coef\n",
      "0                      server -0.728680\n",
      "6                    p2_games -0.080718\n",
      "7                     p1_sets  0.068753\n",
      "5                    p1_games  0.062407\n",
      "12        prev_point_duration -0.047073\n",
      "16             prev_speed_mph  0.019502\n",
      "19  prev_return_depth_encoded -0.018932\n",
      "13       prev_p1_distance_run  0.006415\n",
      "10                is_tiebreak  0.003445\n",
      "3                     game_no  0.000000\n",
      "1                    serve_no  0.000000\n",
      "2                      set_no  0.000000\n",
      "11                   is_deuce  0.000000\n",
      "9              is_break_point  0.000000\n",
      "8                     p2_sets  0.000000\n",
      "4                    point_no  0.000000\n",
      "15           prev_rally_count  0.000000\n",
      "14       prev_p2_distance_run  0.000000\n",
      "17   prev_serve_width_encoded  0.000000\n",
      "18   prev_serve_depth_encoded  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5. LASSO Logistic 回归\n",
    "# =========================\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        solver=\"liblinear\",   # 或 saga\n",
    "        C=0.05,                # 正则强度，可交叉验证\n",
    "        max_iter=2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# 6. 评估\n",
    "# =========================\n",
    "proba_test = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Log loss :\", log_loss(y_test, proba_test))\n",
    "print(\"Brier    :\", brier_score_loss(y_test, proba_test))\n",
    "print(\"ROC AUC  :\", roc_auc_score(y_test, proba_test))\n",
    "\n",
    "# =========================\n",
    "# 7. LASSO 选出来的特征\n",
    "# =========================\n",
    "coef = pipe.named_steps[\"clf\"].coef_.flatten()\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"coef\": coef\n",
    "}).sort_values(\"coef\", key=np.abs, ascending=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "028490df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC  : 0.7065027907876781\n",
      "                      feature  importance\n",
      "0                      server    0.114743\n",
      "14       prev_p2_distance_run    0.107708\n",
      "13       prev_p1_distance_run    0.107345\n",
      "4                    point_no    0.101403\n",
      "12        prev_point_duration    0.099525\n",
      "16             prev_speed_mph    0.091447\n",
      "3                     game_no    0.048781\n",
      "15           prev_rally_count    0.045939\n",
      "1                    serve_no    0.042774\n",
      "17   prev_serve_width_encoded    0.041049\n",
      "5                    p1_games    0.039604\n",
      "6                    p2_games    0.038330\n",
      "19  prev_return_depth_encoded    0.023965\n",
      "2                      set_no    0.023551\n",
      "8                     p2_sets    0.019264\n",
      "7                     p1_sets    0.018767\n",
      "18   prev_serve_depth_encoded    0.017721\n",
      "10                is_tiebreak    0.009264\n",
      "9              is_break_point    0.008821\n",
      "11                   is_deuce    0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "proba_test = clf.predict_proba(X_test)[:, 1]\n",
    "# output roc_auc_score and feature importance\n",
    "roc_auc = roc_auc_score(y_test, proba_test)\n",
    "feature_importances = clf.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": feature_importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "print(\"ROC AUC  :\", roc_auc)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55579417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "完整特征集 LASSO 模型结果\n",
      "==================================================\n",
      "Log loss : 0.6478882949112373\n",
      "Brier    : 0.2211403993312842\n",
      "ROC AUC  : 0.6791544956268026\n",
      "\n",
      "特征系数（按绝对值排序）：\n",
      "                      feature      coef\n",
      "0                      server -0.722756\n",
      "10        prev_point_duration -0.067815\n",
      "7                      set_no  0.058891\n",
      "14             prev_speed_mph  0.029559\n",
      "17  prev_return_depth_encoded -0.026061\n",
      "5                 is_tiebreak  0.012778\n",
      "11       prev_p1_distance_run  0.010381\n",
      "3                 p2_break_pt  0.008491\n",
      "8                     game_no -0.007484\n",
      "9                    point_no  0.004377\n",
      "1                    serve_no  0.002019\n",
      "15   prev_serve_width_encoded -0.001787\n",
      "2                 p1_break_pt  0.000000\n",
      "4              is_break_point  0.000000\n",
      "6                    is_deuce  0.000000\n",
      "12       prev_p2_distance_run  0.000000\n",
      "13           prev_rally_count  0.000000\n",
      "16   prev_serve_depth_encoded  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 8. LASSO - 使用 H:AM 列范围 + 之前的特征（所有特征）\n",
    "# =========================\n",
    "# H:AM 对应的列（从p1_sets到p2_break_pt_missed）\n",
    "feature_cols_h_am = [\n",
    "    \"server\", \"serve_no\",  # N, O\n",
    "    \"p1_break_pt\", \"p2_break_pt\",  # AH, AI\n",
    "    # 之前的特征\n",
    "    \"is_break_point\", \"is_tiebreak\", \"is_deuce\",\n",
    "    \"set_no\", \"game_no\", \"point_no\",\n",
    "    # 上一分的持续时间\n",
    "    \"prev_point_duration\",\n",
    "    # 上一分的特征（t-1）\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\"\n",
    "]\n",
    "\n",
    "# 准备数据\n",
    "X_combined = df[feature_cols_h_am].copy()\n",
    "\n",
    "# 填充缺失值\n",
    "X_combined = X_combined.fillna(0)\n",
    "\n",
    "# 分割数据\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(\n",
    "    X_combined, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 构建LASSO模型\n",
    "pipe_combined = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        solver=\"liblinear\",\n",
    "        C=0.1,\n",
    "        max_iter=2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_combined.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# 评估\n",
    "proba_test_combined = pipe_combined.predict_proba(X_test_combined)[:, 1]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"完整特征集 LASSO 模型结果\")\n",
    "print(\"=\"*50)\n",
    "print(\"Log loss :\", log_loss(y_test_combined, proba_test_combined))\n",
    "print(\"Brier    :\", brier_score_loss(y_test_combined, proba_test_combined))\n",
    "print(\"ROC AUC  :\", roc_auc_score(y_test_combined, proba_test_combined))\n",
    "\n",
    "# 特征重要性\n",
    "coef_combined = pipe_combined.named_steps[\"clf\"].coef_.flatten()\n",
    "coef_df_combined = pd.DataFrame({\n",
    "    \"feature\": feature_cols_h_am,\n",
    "    \"coef\": coef_combined\n",
    "}).sort_values(\"coef\", key=np.abs, ascending=False)\n",
    "\n",
    "print(\"\\n特征系数（按绝对值排序）：\")\n",
    "print(coef_df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1c87f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "动量-残差 ARX 拟合结果（填补 NaN 后）\n",
      "==================================================\n",
      "RMSE(resid): 0.21876928506453636\n",
      "R^2(resid) : 0.002051207375882047\n",
      "         phi(resid_prev) : +0.024058\n",
      "gamma(prev_point_duration) : +0.000011\n",
      "gamma(prev_p1_distance_run) : +0.000963\n",
      "gamma(prev_p2_distance_run) : -0.002008\n",
      " gamma(prev_rally_count) : +0.004980\n",
      "   gamma(prev_speed_mph) : +0.000016\n",
      "gamma(prev_serve_width_encoded) : -0.005134\n",
      "gamma(prev_serve_depth_encoded) : -0.007494\n",
      "gamma(prev_return_depth_encoded) : -0.000251\n",
      "截距(intercept)     : +0.021570\n",
      "\n",
      "--------------------------------------------------\n",
      "在ARX可用样本上的评估（基线 vs 动量修正）\n",
      "--------------------------------------------------\n",
      "Baseline  LogLoss: 0.6329426245832419\n",
      "Momentum  LogLoss: 0.6290513036356817\n",
      "Baseline  Brier  : 0.21927296374244018\n",
      "Momentum  Brier  : 0.21876928506453636\n",
      "Baseline  ROC AUC: 0.689074493651666\n",
      "Momentum  ROC AUC: 0.6934649708158597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "动量 M_t 概要（NaN 已填补）：\n",
      "count    7284.000000\n",
      "mean       -0.014677\n",
      "std         0.017967\n",
      "min        -0.202318\n",
      "25%        -0.020657\n",
      "50%        -0.014946\n",
      "75%        -0.007561\n",
      "max         0.937337\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 9. 动量-残差 ARX（惯性 + 外生输入）\n",
    "# 修正：对 u_prev 特征先填充缺失，确保 M_t 不被 NaN 传播；按比赛内顺序递推\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1) 逻辑回归在全样本的残差 r_t = y_t - p_hat_t\n",
    "proba_all = pipe.predict_proba(X)[:, 1]\n",
    "df[\"resid\"] = y - proba_all\n",
    "\n",
    "# 2) 构造 ARX 输入：r_{t-1} 与 u_{t-1}\n",
    "u_prev_cols = [\n",
    "    \"prev_point_duration\",\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\",\n",
    " ]\n",
    "\n",
    "# 关键修正：先处理缺失（首分的 prev_* 等结构性缺失全部置 0）\n",
    "df[u_prev_cols] = df[u_prev_cols].fillna(0)\n",
    "\n",
    "# 按比赛内顺序排序，避免乱序导致递推不一致\n",
    "df_sorted = df.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\")\n",
    "\n",
    "df_sorted[\"resid_prev\"] = df_sorted.groupby(\"match_id\")[\"resid\"].shift(1)\n",
    "\n",
    "use_cols = [\"resid\", \"resid_prev\"] + u_prev_cols\n",
    "arx_df = df_sorted[use_cols].copy().dropna()\n",
    "\n",
    "Z = arx_df[[\"resid_prev\"] + u_prev_cols].values\n",
    "r = arx_df[\"resid\"].values\n",
    "\n",
    "# 3) 拟合线性 ARX：r_t = φ r_{t-1} + γ^T u_{t-1} + e_t\n",
    "arx = LinearRegression()\n",
    "arx.fit(Z, r)\n",
    "\n",
    "r_hat = arx.predict(Z)\n",
    "rmse = mean_squared_error(r, r_hat)\n",
    "r2 = r2_score(r, r_hat)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"动量-残差 ARX 拟合结果（填补 NaN 后）\")\n",
    "print(\"=\"*50)\n",
    "print(\"RMSE(resid):\", rmse)\n",
    "print(\"R^2(resid) :\", r2)\n",
    "\n",
    "coef_names = [\"phi(resid_prev)\"] + [f\"gamma({c})\" for c in u_prev_cols]\n",
    "coef_vals = np.concatenate(([arx.coef_[0]], arx.coef_[1:]))\n",
    "for name, val in zip(coef_names, coef_vals):\n",
    "    print(f\"{name:>24} : {val:+.6f}\")\n",
    "print(f\"截距(intercept)     : {arx.intercept_:+.6f}\")\n",
    "\n",
    "# 4) 用 r_hat 调整逻辑概率：p_adj = clip(p_hat + r_hat)\n",
    "idx = arx_df.index\n",
    "p_base_series = pd.Series(proba_all, index=df.index)\n",
    "y_series = pd.Series(y, index=df.index)\n",
    "p_base_sub = p_base_series.loc[idx].values\n",
    "p_adj_sub = np.clip(p_base_sub + r_hat, 1e-6, 1 - 1e-6)\n",
    "y_sub = y_series.loc[idx].values\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"在ARX可用样本上的评估（基线 vs 动量修正）\")\n",
    "print(\"-\"*50)\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score\n",
    "print(\"Baseline  LogLoss:\", log_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  LogLoss:\", log_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  Brier  :\", brier_score_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  Brier  :\", brier_score_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  ROC AUC:\", roc_auc_score(y_sub, p_base_sub))\n",
    "print(\"Momentum  ROC AUC:\", roc_auc_score(y_sub, p_adj_sub))\n",
    "\n",
    "# 5) 按比赛顺序递推动量 M_t（避免 NaN 传染）\n",
    "Mt = pd.Series(np.nan, index=df_sorted.index, dtype=float)\n",
    "phi = arx.coef_[0]\n",
    "gamma = arx.coef_[1:]\n",
    "\n",
    "for mid, g in df_sorted.groupby(\"match_id\"):\n",
    "    prev_idx = None\n",
    "    for idx_i in g.index:\n",
    "        if prev_idx is None:\n",
    "            Mt.loc[idx_i] = 0.0\n",
    "        else:\n",
    "            u_prev = df_sorted.loc[idx_i, u_prev_cols].values.astype(float)\n",
    "            Mt.loc[idx_i] = phi * Mt.loc[prev_idx] + gamma.dot(u_prev)\n",
    "        prev_idx = idx_i\n",
    "\n",
    "print(\"\\n动量 M_t 概要（NaN 已填补）：\")\n",
    "print(Mt.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d6d63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, ELBO: 7896.1943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 500, ELBO: 4868.6536\n",
      "step 1000, ELBO: 4830.9214\n",
      "step 1500, ELBO: 4874.3820\n",
      "step 2000, ELBO: 4847.4321\n",
      "step 2500, ELBO: 4834.0796\n",
      "step 3000, ELBO: 4834.7965\n",
      "step 3500, ELBO: 4836.2212\n",
      "\n",
      "贝叶斯残差参数（均值场近似）：\n",
      "phi        : 0.02622678130865097\n",
      "gamma mean : [-0.00202654  0.01070918 -0.03008662  0.02173747 -0.00106413 -0.00753236\n",
      " -0.00696774  0.00149173]\n",
      "sigma med  : 0.46769553422927856\n",
      "\n",
      "评估（基线 vs 贝叶斯动量 logit 修正）\n",
      "Baseline  LogLoss: 0.6329426245832419\n",
      "Momentum  LogLoss: 0.6327635669380978\n",
      "Baseline  Brier  : 0.21927296374244018\n",
      "Momentum  Brier  : 0.21918424058784988\n",
      "Baseline  ROC AUC: 0.689074493651666\n",
      "Momentum  ROC AUC: 0.6903435214616473\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 10. 贝叶斯残差模型（Pyro）\n",
    "# 修正：排序+分组递推，u_prev 标准化，小尺度先验，稳定学习率\n",
    "# =========================\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import ClippedAdam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 基础残差\n",
    "proba_all = pipe.predict_proba(X)[:, 1]\n",
    "df[\"resid\"] = y - proba_all\n",
    "\n",
    "u_prev_cols = [\n",
    "    \"prev_point_duration\",\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\",\n",
    "]\n",
    "\n",
    "# 1) 排序 + shift，且先填补 prev_* 缺失\n",
    "a = df.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\").copy()\n",
    "a[u_prev_cols] = a[u_prev_cols].fillna(0)\n",
    "a[\"resid_prev\"] = a.groupby(\"match_id\")[\"resid\"].shift(1)\n",
    "\n",
    "# 2) 构造用于 Pyro 的表，保留 match_id 以便分组递推\n",
    "b = a[[\"match_id\", \"resid\", \"resid_prev\"] + u_prev_cols].dropna(subset=[\"resid_prev\"])\n",
    "\n",
    "# 3) 标准化 u_prev（避免尺度失配导致 sigma 爆炸）；resid 本身在 [-1,1]，无需缩放\n",
    "sc_U = StandardScaler()\n",
    "U_prev_std = sc_U.fit_transform(b[u_prev_cols].values.astype(float))\n",
    "\n",
    "r_t = torch.tensor(b[\"resid\"].values, dtype=torch.float32)\n",
    "r_prev = torch.tensor(b[\"resid_prev\"].values, dtype=torch.float32)\n",
    "U_prev = torch.tensor(U_prev_std, dtype=torch.float32)\n",
    "\n",
    "# 模型：r_t ~ Normal(phi * r_{t-1} + gamma^T u_{t-1}, sigma)\n",
    "def model(r_prev, U_prev, r_t):\n",
    "    phi = pyro.sample(\"phi\", dist.Normal(0.0, 1.0))\n",
    "    gamma = pyro.sample(\"gamma\", dist.Normal(torch.zeros(U_prev.shape[1]), torch.ones(U_prev.shape[1])).to_event(1))\n",
    "    sigma = pyro.sample(\"sigma\", dist.HalfNormal(0.5))  # 更小的先验尺度\n",
    "    mu = phi * r_prev + (U_prev @ gamma)\n",
    "    with pyro.plate(\"data\", len(r_t)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mu, sigma), obs=r_t)\n",
    "\n",
    "# 引导：对 sigma 用 LogNormal 形式更稳定\n",
    "def guide(r_prev, U_prev, r_t):\n",
    "    phi_loc = pyro.param(\"phi_loc\", torch.tensor(0.0))\n",
    "    phi_scale = pyro.param(\"phi_scale\", torch.tensor(0.1), constraint=dist.constraints.positive)\n",
    "    gamma_loc = pyro.param(\"gamma_loc\", torch.zeros(U_prev.shape[1]))\n",
    "    gamma_scale = pyro.param(\"gamma_scale\", torch.ones(U_prev.shape[1]) * 0.1, constraint=dist.constraints.positive)\n",
    "    sigma_loc = pyro.param(\"sigma_loc\", torch.tensor(-1.0))\n",
    "    sigma_scale = pyro.param(\"sigma_scale\", torch.tensor(0.2), constraint=dist.constraints.positive)\n",
    "    pyro.sample(\"phi\", dist.Normal(phi_loc, phi_scale))\n",
    "    pyro.sample(\"gamma\", dist.Normal(gamma_loc, gamma_scale).to_event(1))\n",
    "    pyro.sample(\"sigma\", dist.LogNormal(sigma_loc, sigma_scale))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "optimizer = ClippedAdam({\"lr\": 0.005})\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "for step in range(4000):\n",
    "    loss = svi.step(r_prev, U_prev, r_t)\n",
    "    if step % 500 == 0:\n",
    "        print(f\"step {step}, ELBO: {loss:.4f}\")\n",
    "\n",
    "phi_est = pyro.param(\"phi_loc\").item()\n",
    "gamma_est = pyro.param(\"gamma_loc\").detach().numpy()\n",
    "sigma_med = float(torch.exp(pyro.param(\"sigma_loc\")))  # LogNormal 的中位数\n",
    "print(\"\\n贝叶斯残差参数（均值场近似）：\")\n",
    "print(\"phi        :\", phi_est)\n",
    "print(\"gamma mean :\", gamma_est)\n",
    "print(\"sigma med  :\", sigma_med)\n",
    "\n",
    "# 4) 按比赛分组递推动量 M_t（使用标准化后的 u_prev）\n",
    "phi = float(phi_est)\n",
    "gamma = gamma_est.astype(float)\n",
    "U_std_df = pd.DataFrame(U_prev_std, index=b.index, columns=u_prev_cols)\n",
    "Mt_sub = np.zeros(len(b), dtype=float)\n",
    "pos_map = {idx: i for i, idx in enumerate(b.index)}\n",
    "\n",
    "for mid, g in b.groupby(\"match_id\", sort=False):\n",
    "    idxs = g.index.to_list()\n",
    "    for j, idx_row in enumerate(idxs):\n",
    "        pos = pos_map[idx_row]\n",
    "        if j == 0:\n",
    "            Mt_sub[pos] = 0.0\n",
    "        else:\n",
    "            u_vec = U_std_df.loc[idx_row].values.astype(float)\n",
    "            prev_pos = pos_map[idxs[j - 1]]\n",
    "            Mt_sub[pos] = phi * Mt_sub[prev_pos] + gamma.dot(u_vec)\n",
    "\n",
    "alpha = 1.0\n",
    "p_base_series = pd.Series(proba_all, index=df.index)\n",
    "y_series = pd.Series(y, index=df.index)\n",
    "p_base_sub = p_base_series.loc[b.index].values\n",
    "y_sub = y_series.loc[b.index].values\n",
    "\n",
    "logit_base_sub = np.log(p_base_sub / (1.0 - p_base_sub))\n",
    "logit_adj_sub = logit_base_sub + alpha * Mt_sub\n",
    "p_adj_sub = 1.0 / (1.0 + np.exp(-logit_adj_sub))\n",
    "\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score\n",
    "print(\"\\n评估（基线 vs 贝叶斯动量 logit 修正）\")\n",
    "print(\"Baseline  LogLoss:\", log_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  LogLoss:\", log_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  Brier  :\", brier_score_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  Brier  :\", brier_score_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  ROC AUC:\", roc_auc_score(y_sub, p_base_sub))\n",
    "print(\"Momentum  ROC AUC:\", roc_auc_score(y_sub, p_adj_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec9c5f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[控制基线] Group 留出评估\n",
      "LogLoss: 0.6385095985692272\n",
      "Brier  : 0.22294783417803687\n",
      "ROC AUC: 0.6684337863801324\n",
      "\n",
      "[控制基线] 残差 ARX 结果\n",
      "RMSE(resid): 0.21881256824102302\n",
      "R^2(resid) : 0.002039250008656457\n",
      "phi(resid_prev): 0.02552900895127678\n",
      "截距: 5.844290503978066e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 11. 实验A：控制基线（无 prev_*） + 残差动量 sanity check\n",
    "# 目的：把短期记忆从 baseline 拿掉，看残差是否更可预测\n",
    "# =========================\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "control_cols = [\n",
    "    \"server\", \"serve_no\",\n",
    "    \"set_no\", \"game_no\", \"point_no\",\n",
    "    \"p1_games\", \"p2_games\", \"p1_sets\", \"p2_sets\",\n",
    "    \"is_break_point\", \"is_tiebreak\", \"is_deuce\",\n",
    " ]\n",
    "\n",
    "X_ctrl = df[control_cols].copy().fillna(0)\n",
    "groups = df[\"match_id\"].values\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X_ctrl, y, groups))\n",
    "\n",
    "Xc_train, Xc_test = X_ctrl.iloc[train_idx], X_ctrl.iloc[test_idx]\n",
    "yc_train, yc_test = y[train_idx], y[test_idx]\n",
    "\n",
    "pipe_ctrl = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=2000))\n",
    "])\n",
    "pipe_ctrl.fit(Xc_train, yc_train)\n",
    "\n",
    "proba_ctrl_test = pipe_ctrl.predict_proba(Xc_test)[:, 1]\n",
    "print(\"\\n[控制基线] Group 留出评估\")\n",
    "print(\"LogLoss:\", log_loss(yc_test, proba_ctrl_test))\n",
    "print(\"Brier  :\", brier_score_loss(yc_test, proba_ctrl_test))\n",
    "print(\"ROC AUC:\", roc_auc_score(yc_test, proba_ctrl_test))\n",
    "\n",
    "# 全量 residual 用于动量检验\n",
    "proba_ctrl_all = pipe_ctrl.predict_proba(X_ctrl)[:, 1]\n",
    "resid_ctrl = y - proba_ctrl_all\n",
    "\n",
    "# 用和之前相同的 u_prev_cols 测试残差是否更可预测\n",
    "df_ctrl = df.copy()\n",
    "df_ctrl[u_prev_cols] = df_ctrl[u_prev_cols].fillna(0)\n",
    "df_ctrl[\"resid_ctrl\"] = resid_ctrl\n",
    "df_ctrl[\"resid_ctrl_prev\"] = df_ctrl.groupby(\"match_id\")[\"resid_ctrl\"].shift(1)\n",
    "\n",
    "df_ctrl_sorted = df_ctrl.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\")\n",
    "arx_ctrl_df = df_ctrl_sorted[[\"resid_ctrl\", \"resid_ctrl_prev\"] + u_prev_cols].dropna()\n",
    "\n",
    "Zc = arx_ctrl_df[[\"resid_ctrl_prev\"] + u_prev_cols].values\n",
    "rc = arx_ctrl_df[\"resid_ctrl\"].values\n",
    "arx_ctrl = LinearRegression()\n",
    "arx_ctrl.fit(Zc, rc)\n",
    "rh = arx_ctrl.predict(Zc)\n",
    "\n",
    "print(\"\\n[控制基线] 残差 ARX 结果\")\n",
    "print(\"RMSE(resid):\", mean_squared_error(rc, rh))\n",
    "print(\"R^2(resid) :\", r2_score(rc, rh))\n",
    "print(\"phi(resid_prev):\", arx_ctrl.coef_[0])\n",
    "print(\"截距:\", arx_ctrl.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba92db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[事件驱动动量] 残差 ARX\n",
      "RMSE(resid): 0.21867270514174433\n",
      "R^2(resid) : 0.002491771129215059\n",
      "phi(resid_prev): 0.034823712345831766\n",
      "Top事件系数：\n",
      "         prev_p2_unf_err : -0.0146\n",
      "    prev_p1_double_fault : +0.0099\n",
      "    prev_p2_double_fault : +0.0077\n",
      "             prev_p2_ace : -0.0075\n",
      "    prev_p2_break_pt_won : +0.0071\n",
      "         prev_p1_unf_err : -0.0066\n",
      "          prev_p2_winner : +0.0051\n",
      "          prev_p1_winner : +0.0043\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 12. 实验B：事件驱动的 u_prev（ace/DF/winner/UE/break miss），检验是否带来更强动量\n",
    "# =========================\n",
    "candidate_events = [\n",
    "    \"p1_ace\", \"p2_ace\",\n",
    "    \"p1_double_fault\", \"p2_double_fault\",\n",
    "    \"p1_winner\", \"p2_winner\",\n",
    "    \"p1_unf_err\", \"p2_unf_err\",\n",
    "    \"p1_break_pt_missed\", \"p2_break_pt_missed\",\n",
    "    \"p1_break_pt_won\", \"p2_break_pt_won\",\n",
    "]\n",
    "\n",
    "event_cols = [c for c in candidate_events if c in df.columns]\n",
    "if not event_cols:\n",
    "    print(\"未找到事件类列，跳过实验B\")\n",
    "else:\n",
    "    df_ev = df.copy()\n",
    "    # 为事件列构造上一分特征\n",
    "    for c in event_cols:\n",
    "        df_ev[f\"prev_{c}\"] = df_ev.groupby(\"match_id\")[c].shift(1)\n",
    "    u_prev_events = [f\"prev_{c}\" for c in event_cols]\n",
    "\n",
    "    df_ev[u_prev_events] = df_ev[u_prev_events].fillna(0)\n",
    "    df_ev[\"resid_base\"] = y - pipe.predict_proba(X)[:, 1]\n",
    "    df_ev[\"resid_base_prev\"] = df_ev.groupby(\"match_id\")[\"resid_base\"].shift(1)\n",
    "\n",
    "    df_ev_sorted = df_ev.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\")\n",
    "    ev_df = df_ev_sorted[[\"match_id\", \"resid_base\", \"resid_base_prev\"] + u_prev_events].dropna(subset=[\"resid_base_prev\"])\n",
    "\n",
    "    # 标准化事件驱动特征\n",
    "    sc_ev = StandardScaler()\n",
    "    Ue = sc_ev.fit_transform(ev_df[u_prev_events].values.astype(float))\n",
    "    re = ev_df[\"resid_base\"].values\n",
    "    re_prev = ev_df[\"resid_base_prev\"].values\n",
    "    Z_evt = np.column_stack([re_prev, Ue])\n",
    "\n",
    "    arx_ev = LinearRegression()\n",
    "    arx_ev.fit(Z_evt, re)\n",
    "    r_hat_ev = arx_ev.predict(Z_evt)\n",
    "\n",
    "    print(\"\\n[事件驱动动量] 残差 ARX\")\n",
    "    print(\"RMSE(resid):\", mean_squared_error(re, r_hat_ev))\n",
    "    print(\"R^2(resid) :\", r2_score(re, r_hat_ev))\n",
    "    print(\"phi(resid_prev):\", arx_ev.coef_[0])\n",
    "    # 输出最重要的事件驱动系数\n",
    "    gamma_ev = arx_ev.coef_[1:]\n",
    "    topk = min(8, len(u_prev_events))\n",
    "    idx_sorted = np.argsort(-np.abs(gamma_ev))[:topk]\n",
    "    print(\"Top事件系数：\")\n",
    "    for i in idx_sorted:\n",
    "        print(f\"{u_prev_events[i]:>24} : {gamma_ev[i]:+0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73d34e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18, ELBO: 47643.316"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     97\u001b[39m n_steps = \u001b[32m150\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps):\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     loss = \u001b[43msvi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctrl_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, ELBO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,end=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# 取 posterior 平均的 logits 进行评估\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyro/infer/svi.py:145\u001b[39m, in \u001b[36mSVI.step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m poutine.trace(param_only=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m params = \u001b[38;5;28mset\u001b[39m(\n\u001b[32m    148\u001b[39m     site[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m].unconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture.trace.nodes.values()\n\u001b[32m    149\u001b[39m )\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyro/infer/trace_elbo.py:157\u001b[39m, in \u001b[36mTrace_ELBO.loss_and_grads\u001b[39m\u001b[34m(self, model, guide, *args, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainable_params \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    154\u001b[39m         surrogate_loss_particle, \u001b[33m\"\u001b[39m\u001b[33mrequires_grad\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    155\u001b[39m     ):\n\u001b[32m    156\u001b[39m         surrogate_loss_particle = surrogate_loss_particle / \u001b[38;5;28mself\u001b[39m.num_particles\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[43msurrogate_loss_particle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m warn_if_nan(loss, \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyro/util.py:119\u001b[39m, in \u001b[36mwarn_if_inf.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    115\u001b[39m         lineno = frame.f_lineno\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.is_tensor(value) \u001b[38;5;129;01mand\u001b[39;00m value.requires_grad:\n\u001b[32m    118\u001b[39m     value.register_hook(\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: warn_if_inf(\n\u001b[32m    120\u001b[39m             x,\n\u001b[32m    121\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbackward \u001b[39m\u001b[33m\"\u001b[39m + msg,\n\u001b[32m    122\u001b[39m             allow_posinf,\n\u001b[32m    123\u001b[39m             allow_neginf,\n\u001b[32m    124\u001b[39m             filename=filename,\n\u001b[32m    125\u001b[39m             lineno=lineno,\n\u001b[32m    126\u001b[39m         )\n\u001b[32m    127\u001b[39m     )\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m allow_posinf) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    130\u001b[39m     value == math.inf\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, numbers.Number)\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (value == math.inf).any()\n\u001b[32m    133\u001b[39m ):\n\u001b[32m    134\u001b[39m     warnings.warn_explicit(\n\u001b[32m    135\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEncountered +inf\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m + msg \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    136\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    137\u001b[39m         filename,\n\u001b[32m    138\u001b[39m         lineno,\n\u001b[32m    139\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 13. DBN：控制基线 + 标量动量 M_t（logit 空间联合训练）\n",
    "# 说明：\n",
    "# - baseline 只含控制变量（server/score/importance），不含任何 prev_*\n",
    "# - 短期/事件信号放入动量驱动 u_{t-1}，M_t 在 log-odds 上直接作用\n",
    "# - 使用 Pyro + AutoNormal 变分；如需严格分组留出，可先过滤 match_id 再训练\n",
    "# =========================\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "# 控制变量（弱化 baseline）\n",
    "ctrl_cols = [\n",
    "    \"server\", \"serve_no\",\n",
    "    \"set_no\", \"game_no\", \"point_no\",\n",
    "    \"p1_games\", \"p2_games\", \"p1_sets\", \"p2_sets\",\n",
    "    \"is_break_point\", \"is_tiebreak\", \"is_deuce\",\n",
    "]\n",
    "\n",
    "# 事件驱动 + 体能/发球状态驱动（上一分/窗口）\n",
    "event_cols = [c for c in [\n",
    "    \"p1_ace\", \"p2_ace\",\n",
    "    \"p1_double_fault\", \"p2_double_fault\",\n",
    "    \"p1_winner\", \"p2_winner\",\n",
    "    \"p1_unf_err\", \"p2_unf_err\",\n",
    "    \"p1_break_pt_missed\", \"p2_break_pt_missed\",\n",
    "    \"p1_break_pt_won\", \"p2_break_pt_won\",\n",
    "] if c in df.columns]\n",
    "\n",
    "df_m = df.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\").copy()\n",
    "\n",
    "# 构造上一分事件特征\n",
    "for c in event_cols:\n",
    "    df_m[f\"prev_{c}\"] = df_m.groupby(\"match_id\")[c].shift(1)\n",
    "\n",
    "# 构造简单 EWMA（疲劳/发球状态），并 shift(1) 防泄漏\n",
    "def ewm_prev(series, span=5):\n",
    "    return series.shift(1).ewm(span=span, adjust=False).mean()\n",
    "\n",
    "df_m[\"rally_ewm\"] = df_m.groupby(\"match_id\")[\"rally_count\"].transform(lambda s: ewm_prev(s, span=6))\n",
    "df_m[\"dist_ewm\"] = df_m.groupby(\"match_id\")[\"p1_distance_run\"].transform(lambda s: ewm_prev(s, span=6))\n",
    "df_m[\"serve_speed_ewm\"] = df_m.groupby(\"match_id\")[\"speed_mph\"].transform(lambda s: ewm_prev(s, span=6))\n",
    "\n",
    "u_cols = []\n",
    "u_cols += [f\"prev_{c}\" for c in event_cols]\n",
    "u_cols += [\"rally_ewm\", \"dist_ewm\", \"serve_speed_ewm\"]\n",
    "\n",
    "df_m[u_cols] = df_m[u_cols].fillna(0)\n",
    "\n",
    "# 设计矩阵\n",
    "X_ctrl = df_m[ctrl_cols].fillna(0).values\n",
    "U_drv = df_m[u_cols].values\n",
    "y_arr = df_m[\"y\"].values.astype(float)\n",
    "\n",
    "# match_id 编码为整数\n",
    "match_codes, match_uniques = pd.factorize(df_m[\"match_id\"], sort=False)\n",
    "\n",
    "# 标准化驱动项\n",
    "sc_u = StandardScaler()\n",
    "U_std = sc_u.fit_transform(U_drv)\n",
    "\n",
    "ctrl_tensor = torch.tensor(X_ctrl, dtype=torch.float32)\n",
    "u_tensor = torch.tensor(U_std, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_arr, dtype=torch.float32)\n",
    "match_tensor = torch.tensor(match_codes, dtype=torch.long)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "def dbn_model(ctrl, u, match_ids, y):\n",
    "    T, p = ctrl.shape\n",
    "    q = u.shape[1]\n",
    "    beta = pyro.sample(\"beta\", dist.Normal(0.0, 1.0).expand([p]).to_event(1))\n",
    "    rho = pyro.sample(\"rho\", dist.Normal(0.0, 0.3))\n",
    "    eta = pyro.sample(\"eta\", dist.Normal(0.0, 1.0).expand([q]).to_event(1))\n",
    "    sigma_M = pyro.sample(\"sigma_M\", dist.HalfNormal(0.5))\n",
    "    logits = []\n",
    "    M_prev = torch.tensor(0.0)\n",
    "    last_mid = match_ids[0] if T > 0 else -1\n",
    "    for t in range(T):\n",
    "        if match_ids[t] != last_mid:\n",
    "            M_prev = torch.tensor(0.0)\n",
    "            last_mid = match_ids[t]\n",
    "        mean_M = rho * M_prev + (u[t] @ eta)\n",
    "        M_t = pyro.sample(f\"M_{t}\", dist.Normal(mean_M, sigma_M))\n",
    "        logit_t = (ctrl[t] @ beta) + M_t\n",
    "        pyro.sample(f\"y_{t}\", dist.Bernoulli(logits=logit_t), obs=y[t])\n",
    "        logits.append(logit_t)\n",
    "        M_prev = M_t\n",
    "    return torch.stack(logits) if logits else torch.tensor([])\n",
    "\n",
    "guide = pyro.infer.autoguide.AutoNormal(dbn_model)\n",
    "optimizer = ClippedAdam({\"lr\": 0.003})\n",
    "svi = SVI(dbn_model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 150\n",
    "for step in range(n_steps):\n",
    "    loss = svi.step(ctrl_tensor, u_tensor, match_tensor, y_tensor)\n",
    "    print(f\"\\rstep {step}, ELBO: {loss:.2f}\",end='')\n",
    "\n",
    "# 取 posterior 平均的 logits 进行评估\n",
    "predictive = Predictive(dbn_model, guide=guide, params=pyro.get_param_store(), num_samples=50)\n",
    "samples = predictive(ctrl_tensor, u_tensor, match_tensor, y_tensor)\n",
    "logits_mc = samples[\"_RETURN\"]  # [S, T]\n",
    "p_mc = torch.sigmoid(logits_mc)\n",
    "p_mean = p_mc.mean(0).detach().numpy()\n",
    "y_np = y_tensor.numpy()\n",
    "\n",
    "print(\"\\n[DBN 动量] 全量评估 (提醒：当前未做 match 留出)\")\n",
    "print(\"LogLoss:\", log_loss(y_np, p_mean))\n",
    "print(\"Brier  :\", brier_score_loss(y_np, p_mean))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_np, p_mean))\n",
    "\n",
    "# 导出动量均值曲线用于可视化/反转分析\n",
    "Mt_mean = torch.stack([samples[k] for k in samples if k.startswith(\"M_\")]).mean(0).detach().numpy()\n",
    "df_m[\"Mt_mean\"] = Mt_mean\n",
    "print(\"\\n动量 M_t 概要：\")\n",
    "print(df_m[\"Mt_mean\"].describe())\n",
    "print(\"提示：如需严格评估，请先按 match_id 过滤训练/验证，再各自跑一遍 SVI 与预测。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
