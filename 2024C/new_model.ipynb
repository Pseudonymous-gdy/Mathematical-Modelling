{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score\n",
    "\n",
    "# =========================\n",
    "# 1. 读数据\n",
    "# =========================\n",
    "try:\n",
    "    df = pd.read_csv(\"2024_Wimbledon_featured_matches.csv\")\n",
    "except:\n",
    "    df = pd.read_csv(\"Wimbledon_featured_matches.csv\")\n",
    "\n",
    "# =========================\n",
    "# 2. 目标变量\n",
    "# =========================\n",
    "# 假设 point_victor: 1 = P1 赢分, 2 = P2 赢分\n",
    "df = df[df[\"point_victor\"].isin([1, 2])]\n",
    "df[\"y\"] = (df[\"point_victor\"] == 1).astype(int)\n",
    "\n",
    "# =========================\n",
    "# 3. 构造\"无记忆\"特征\n",
    "# =========================\n",
    "# 构造缺失的特征\n",
    "df[\"is_break_point\"] = ((df[\"p1_break_pt\"] > 0) | (df[\"p2_break_pt\"] > 0)).astype(int)\n",
    "df[\"is_tiebreak\"] = (\n",
    "    (df[\"p1_games\"] >= 6)\n",
    "    & (df[\"p2_games\"] >= 6)\n",
    "    & (df[\"p1_games\"].sub(df[\"p2_games\"]).abs() <= 1)\n",
    ").astype(int)\n",
    "df[\"is_deuce\"] = ((df[\"p1_score\"] == \"D\") | (df[\"p2_score\"] == \"D\")).astype(int)\n",
    "\n",
    "# 计算上一分的持续时间\n",
    "df[\"elapsed_seconds\"] = pd.to_timedelta(df[\"elapsed_time\"]).dt.total_seconds()\n",
    "df[\"point_duration\"] = df.groupby(\"match_id\")[\"elapsed_seconds\"].diff()\n",
    "df[\"prev_point_duration\"] = df.groupby(\"match_id\")[\"point_duration\"].shift(1)\n",
    "\n",
    "# 编码分类变量\n",
    "le_serve_width = LabelEncoder()\n",
    "le_serve_depth = LabelEncoder()\n",
    "le_return_depth = LabelEncoder()\n",
    "\n",
    "df[\"serve_width_encoded\"] = le_serve_width.fit_transform(df[\"serve_width\"].astype(str))\n",
    "df[\"serve_depth_encoded\"] = le_serve_depth.fit_transform(df[\"serve_depth\"].astype(str))\n",
    "df[\"return_depth_encoded\"] = le_return_depth.fit_transform(df[\"return_depth\"].astype(str))\n",
    "\n",
    "# 获取上一分的特征值（t-1）\n",
    "df[\"prev_p1_distance_run\"] = df.groupby(\"match_id\")[\"p1_distance_run\"].shift(1)\n",
    "df[\"prev_p2_distance_run\"] = df.groupby(\"match_id\")[\"p2_distance_run\"].shift(1)\n",
    "df[\"prev_rally_count\"] = df.groupby(\"match_id\")[\"rally_count\"].shift(1)\n",
    "df[\"prev_speed_mph\"] = df.groupby(\"match_id\")[\"speed_mph\"].shift(1)\n",
    "df[\"prev_serve_width_encoded\"] = df.groupby(\"match_id\")[\"serve_width_encoded\"].shift(1)\n",
    "df[\"prev_serve_depth_encoded\"] = df.groupby(\"match_id\")[\"serve_depth_encoded\"].shift(1)\n",
    "df[\"prev_return_depth_encoded\"] = df.groupby(\"match_id\")[\"return_depth_encoded\"].shift(1)\n",
    "\n",
    "feature_cols = [\n",
    "    # 发球\n",
    "    \"server\",\n",
    "    \"serve_no\",\n",
    "\n",
    "    # 比分 / 阶段\n",
    "    \"set_no\",\n",
    "    \"game_no\",\n",
    "    \"point_no\",\n",
    "    \"p1_games\",\n",
    "    \"p2_games\",\n",
    "    \"p1_sets\",\n",
    "    \"p2_sets\",\n",
    "\n",
    "    # 关键分\n",
    "    \"is_break_point\",\n",
    "    \"is_tiebreak\",\n",
    "    \"is_deuce\",\n",
    "    \n",
    "    # 上一分的持续时间\n",
    "    \"prev_point_duration\",\n",
    "    \n",
    "    # 上一分的特征（t-1）\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\"\n",
    " ]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"y\"].values\n",
    "\n",
    "# 缺失值简单处理（baseline）\n",
    "X = X.fillna(0)\n",
    "\n",
    "# =========================\n",
    "# 4. 训练 / 测试切分\n",
    "#    （注意：这里是\"非时序 baseline\"，\n",
    "#     所以允许随机切分）\n",
    "# =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss : 0.6432887749793987\n",
      "Brier    : 0.22109745721440277\n",
      "ROC AUC  : 0.6814246545965692\n",
      "                      feature      coef\n",
      "0                      server -0.728518\n",
      "6                    p2_games -0.073654\n",
      "7                     p1_sets  0.069102\n",
      "5                    p1_games  0.067353\n",
      "12        prev_point_duration -0.047121\n",
      "10                is_tiebreak -0.023538\n",
      "16             prev_speed_mph  0.019187\n",
      "19  prev_return_depth_encoded -0.019165\n",
      "13       prev_p1_distance_run  0.006833\n",
      "3                     game_no  0.000000\n",
      "1                    serve_no  0.000000\n",
      "2                      set_no  0.000000\n",
      "11                   is_deuce  0.000000\n",
      "9              is_break_point  0.000000\n",
      "8                     p2_sets  0.000000\n",
      "4                    point_no  0.000000\n",
      "15           prev_rally_count  0.000000\n",
      "14       prev_p2_distance_run  0.000000\n",
      "17   prev_serve_width_encoded  0.000000\n",
      "18   prev_serve_depth_encoded  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5. LASSO Logistic 回归\n",
    "# =========================\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        solver=\"liblinear\",   # 或 saga\n",
    "        C=0.05,                # 正则强度，可交叉验证\n",
    "        max_iter=2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# 6. 评估\n",
    "# =========================\n",
    "proba_test = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Log loss :\", log_loss(y_test, proba_test))\n",
    "print(\"Brier    :\", brier_score_loss(y_test, proba_test))\n",
    "print(\"ROC AUC  :\", roc_auc_score(y_test, proba_test))\n",
    "\n",
    "# =========================\n",
    "# 7. LASSO 选出来的特征\n",
    "# =========================\n",
    "coef = pipe.named_steps[\"clf\"].coef_.flatten()\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"coef\": coef\n",
    "}).sort_values(\"coef\", key=np.abs, ascending=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028490df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC  : 0.7054745176749886\n",
      "                      feature  importance\n",
      "0                      server    0.113223\n",
      "14       prev_p2_distance_run    0.109447\n",
      "13       prev_p1_distance_run    0.109183\n",
      "4                    point_no    0.101670\n",
      "12        prev_point_duration    0.101123\n",
      "16             prev_speed_mph    0.092422\n",
      "3                     game_no    0.049483\n",
      "15           prev_rally_count    0.046079\n",
      "1                    serve_no    0.043066\n",
      "17   prev_serve_width_encoded    0.041929\n",
      "5                    p1_games    0.038208\n",
      "6                    p2_games    0.037426\n",
      "19  prev_return_depth_encoded    0.024284\n",
      "2                      set_no    0.024078\n",
      "8                     p2_sets    0.020305\n",
      "7                     p1_sets    0.019179\n",
      "18   prev_serve_depth_encoded    0.017587\n",
      "9              is_break_point    0.008836\n",
      "10                is_tiebreak    0.002471\n",
      "11                   is_deuce    0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "proba_test = clf.predict_proba(X_test)[:, 1]\n",
    "# output roc_auc_score and feature importance\n",
    "roc_auc = roc_auc_score(y_test, proba_test)\n",
    "feature_importances = clf.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": feature_importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "print(\"ROC AUC  :\", roc_auc)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55579417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "完整特征集 LASSO 模型结果\n",
      "==================================================\n",
      "Log loss : 0.6482348307294812\n",
      "Brier    : 0.22123164701321874\n",
      "ROC AUC  : 0.6768315617437167\n",
      "\n",
      "特征系数（按绝对值排序）：\n",
      "                      feature      coef\n",
      "0                      server -0.723306\n",
      "10        prev_point_duration -0.068438\n",
      "5                 is_tiebreak -0.038568\n",
      "7                      set_no  0.038470\n",
      "14             prev_speed_mph  0.029687\n",
      "17  prev_return_depth_encoded -0.026369\n",
      "9                    point_no  0.026045\n",
      "11       prev_p1_distance_run  0.011251\n",
      "3                 p2_break_pt  0.006379\n",
      "15   prev_serve_width_encoded -0.002080\n",
      "1                    serve_no  0.001058\n",
      "6                    is_deuce  0.000000\n",
      "2                 p1_break_pt  0.000000\n",
      "4              is_break_point  0.000000\n",
      "8                     game_no  0.000000\n",
      "12       prev_p2_distance_run  0.000000\n",
      "13           prev_rally_count  0.000000\n",
      "16   prev_serve_depth_encoded  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 8. LASSO - 使用 H:AM 列范围 + 之前的特征（所有特征）\n",
    "# =========================\n",
    "# H:AM 对应的列（从p1_sets到p2_break_pt_missed）\n",
    "feature_cols_h_am = [\n",
    "    \"server\", \"serve_no\",  # N, O\n",
    "    \"p1_break_pt\", \"p2_break_pt\",  # AH, AI\n",
    "    # 之前的特征\n",
    "    \"is_break_point\", \"is_tiebreak\", \"is_deuce\",\n",
    "    \"set_no\", \"game_no\", \"point_no\",\n",
    "    # 上一分的持续时间\n",
    "    \"prev_point_duration\",\n",
    "    # 上一分的特征（t-1）\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\"\n",
    "]\n",
    "\n",
    "# 准备数据\n",
    "X_combined = df[feature_cols_h_am].copy()\n",
    "\n",
    "# 填充缺失值\n",
    "X_combined = X_combined.fillna(0)\n",
    "\n",
    "# 分割数据\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(\n",
    "    X_combined, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 构建LASSO模型\n",
    "pipe_combined = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        solver=\"liblinear\",\n",
    "        C=0.1,\n",
    "        max_iter=2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_combined.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# 评估\n",
    "proba_test_combined = pipe_combined.predict_proba(X_test_combined)[:, 1]\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"完整特征集 LASSO 模型结果\")\n",
    "print(\"=\"*50)\n",
    "print(\"Log loss :\", log_loss(y_test_combined, proba_test_combined))\n",
    "print(\"Brier    :\", brier_score_loss(y_test_combined, proba_test_combined))\n",
    "print(\"ROC AUC  :\", roc_auc_score(y_test_combined, proba_test_combined))\n",
    "\n",
    "# 特征重要性\n",
    "coef_combined = pipe_combined.named_steps[\"clf\"].coef_.flatten()\n",
    "coef_df_combined = pd.DataFrame({\n",
    "    \"feature\": feature_cols_h_am,\n",
    "    \"coef\": coef_combined\n",
    "}).sort_values(\"coef\", key=np.abs, ascending=False)\n",
    "\n",
    "print(\"\\n特征系数（按绝对值排序）：\")\n",
    "print(coef_df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c87f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "动量-残差 ARX 拟合结果（填补 NaN 后）\n",
      "==================================================\n",
      "RMSE(resid): 0.21874648831993793\n",
      "R^2(resid) : 0.002048948641190651\n",
      "         phi(resid_prev) : +0.023990\n",
      "gamma(prev_point_duration) : +0.000011\n",
      "gamma(prev_p1_distance_run) : +0.000965\n",
      "gamma(prev_p2_distance_run) : -0.002005\n",
      " gamma(prev_rally_count) : +0.004995\n",
      "   gamma(prev_speed_mph) : +0.000015\n",
      "gamma(prev_serve_width_encoded) : -0.005135\n",
      "gamma(prev_serve_depth_encoded) : -0.007578\n",
      "gamma(prev_return_depth_encoded) : -0.000184\n",
      "截距(intercept)     : +0.021584\n",
      "\n",
      "--------------------------------------------------\n",
      "在ARX可用样本上的评估（基线 vs 动量修正）\n",
      "--------------------------------------------------\n",
      "Baseline  LogLoss: 0.6328916041031911\n",
      "Momentum  LogLoss: 0.6290005943077892\n",
      "Baseline  Brier  : 0.21924998026628892\n",
      "Momentum  Brier  : 0.21874648831993793\n",
      "Baseline  ROC AUC: 0.6893316920107085\n",
      "Momentum  ROC AUC: 0.6937313738485029\n",
      "\n",
      "动量 M_t 概要（NaN 已填补）：\n",
      "count    7284.000000\n",
      "mean       -0.014666\n",
      "std         0.017972\n",
      "min        -0.201889\n",
      "25%        -0.020672\n",
      "50%        -0.014934\n",
      "75%        -0.007548\n",
      "max         0.937301\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 9. 动量-残差 ARX（惯性 + 外生输入）\n",
    "# 修正：对 u_prev 特征先填充缺失，确保 M_t 不被 NaN 传播；按比赛内顺序递推\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1) 逻辑回归在全样本的残差 r_t = y_t - p_hat_t\n",
    "proba_all = pipe.predict_proba(X)[:, 1]\n",
    "df[\"resid\"] = y - proba_all\n",
    "\n",
    "# 2) 构造 ARX 输入：r_{t-1} 与 u_{t-1}\n",
    "u_prev_cols = [\n",
    "    \"prev_point_duration\",\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\",\n",
    " ]\n",
    "\n",
    "# 关键修正：先处理缺失（首分的 prev_* 等结构性缺失全部置 0）\n",
    "df[u_prev_cols] = df[u_prev_cols].fillna(0)\n",
    "\n",
    "# 按比赛内顺序排序，避免乱序导致递推不一致\n",
    "df_sorted = df.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\")\n",
    "\n",
    "df_sorted[\"resid_prev\"] = df_sorted.groupby(\"match_id\")[\"resid\"].shift(1)\n",
    "\n",
    "use_cols = [\"resid\", \"resid_prev\"] + u_prev_cols\n",
    "arx_df = df_sorted[use_cols].copy().dropna()\n",
    "\n",
    "Z = arx_df[[\"resid_prev\"] + u_prev_cols].values\n",
    "r = arx_df[\"resid\"].values\n",
    "\n",
    "# 3) 拟合线性 ARX：r_t = φ r_{t-1} + γ^T u_{t-1} + e_t\n",
    "arx = LinearRegression()\n",
    "arx.fit(Z, r)\n",
    "\n",
    "r_hat = arx.predict(Z)\n",
    "rmse = mean_squared_error(r, r_hat)\n",
    "r2 = r2_score(r, r_hat)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"动量-残差 ARX 拟合结果（填补 NaN 后）\")\n",
    "print(\"=\"*50)\n",
    "print(\"RMSE(resid):\", rmse)\n",
    "print(\"R^2(resid) :\", r2)\n",
    "\n",
    "coef_names = [\"phi(resid_prev)\"] + [f\"gamma({c})\" for c in u_prev_cols]\n",
    "coef_vals = np.concatenate(([arx.coef_[0]], arx.coef_[1:]))\n",
    "for name, val in zip(coef_names, coef_vals):\n",
    "    print(f\"{name:>24} : {val:+.6f}\")\n",
    "print(f\"截距(intercept)     : {arx.intercept_:+.6f}\")\n",
    "\n",
    "# 4) 用 r_hat 调整逻辑概率：p_adj = clip(p_hat + r_hat)\n",
    "idx = arx_df.index\n",
    "p_base_series = pd.Series(proba_all, index=df.index)\n",
    "y_series = pd.Series(y, index=df.index)\n",
    "p_base_sub = p_base_series.loc[idx].values\n",
    "p_adj_sub = np.clip(p_base_sub + r_hat, 1e-6, 1 - 1e-6)\n",
    "y_sub = y_series.loc[idx].values\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"在ARX可用样本上的评估（基线 vs 动量修正）\")\n",
    "print(\"-\"*50)\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score\n",
    "print(\"Baseline  LogLoss:\", log_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  LogLoss:\", log_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  Brier  :\", brier_score_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  Brier  :\", brier_score_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  ROC AUC:\", roc_auc_score(y_sub, p_base_sub))\n",
    "print(\"Momentum  ROC AUC:\", roc_auc_score(y_sub, p_adj_sub))\n",
    "\n",
    "# 5) 按比赛顺序递推动量 M_t（避免 NaN 传染）\n",
    "Mt = pd.Series(np.nan, index=df_sorted.index, dtype=float)\n",
    "phi = arx.coef_[0]\n",
    "gamma = arx.coef_[1:]\n",
    "\n",
    "for mid, g in df_sorted.groupby(\"match_id\"):\n",
    "    prev_idx = None\n",
    "    for idx_i in g.index:\n",
    "        if prev_idx is None:\n",
    "            Mt.loc[idx_i] = 0.0\n",
    "        else:\n",
    "            u_prev = df_sorted.loc[idx_i, u_prev_cols].values.astype(float)\n",
    "            Mt.loc[idx_i] = phi * Mt.loc[prev_idx] + gamma.dot(u_prev)\n",
    "        prev_idx = idx_i\n",
    "\n",
    "print(\"\\n动量 M_t 概要（NaN 已填补）：\")\n",
    "print(Mt.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, ELBO: 5271.4673\n",
      "step 500, ELBO: 4859.6054\n",
      "step 1000, ELBO: 4878.9521\n",
      "step 1500, ELBO: 4836.8450\n",
      "step 2000, ELBO: 4833.1361\n",
      "step 2500, ELBO: 4832.6216\n",
      "step 3000, ELBO: 4829.7414\n",
      "step 3500, ELBO: 4836.2308\n",
      "\n",
      "贝叶斯残差参数（均值场近似）：\n",
      "phi        : 0.012461935169994831\n",
      "gamma mean : [ 0.00766294  0.01376079 -0.03246631  0.01569562 -0.00532553 -0.00986257\n",
      " -0.00322394 -0.00433857]\n",
      "sigma med  : 0.46514245867729187\n",
      "\n",
      "评估（基线 vs 贝叶斯动量 logit 修正）\n",
      "Baseline  LogLoss: 0.6328916041031911\n",
      "Momentum  LogLoss: 0.6326300274087159\n",
      "Baseline  Brier  : 0.21924998026628892\n",
      "Momentum  Brier  : 0.21917407737666814\n",
      "Baseline  ROC AUC: 0.6893316920107085\n",
      "Momentum  ROC AUC: 0.6903257967595897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2038/2778163475.py:75: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  sigma_med = float(torch.exp(pyro.param(\"sigma_loc\")))  # LogNormal 的中位数\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 10. 贝叶斯残差模型（Pyro）\n",
    "# 修正：排序+分组递推，u_prev 标准化，小尺度先验，稳定学习率\n",
    "# =========================\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import ClippedAdam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 基础残差\n",
    "proba_all = pipe.predict_proba(X)[:, 1]\n",
    "df[\"resid\"] = y - proba_all\n",
    "\n",
    "u_prev_cols = [\n",
    "    \"prev_point_duration\",\n",
    "    \"prev_p1_distance_run\",\n",
    "    \"prev_p2_distance_run\",\n",
    "    \"prev_rally_count\",\n",
    "    \"prev_speed_mph\",\n",
    "    \"prev_serve_width_encoded\",\n",
    "    \"prev_serve_depth_encoded\",\n",
    "    \"prev_return_depth_encoded\",\n",
    "]\n",
    "\n",
    "# 1) 排序 + shift，且先填补 prev_* 缺失\n",
    "a = df.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\").copy()\n",
    "a[u_prev_cols] = a[u_prev_cols].fillna(0)\n",
    "a[\"resid_prev\"] = a.groupby(\"match_id\")[\"resid\"].shift(1)\n",
    "\n",
    "# 2) 构造用于 Pyro 的表，保留 match_id 以便分组递推\n",
    "b = a[[\"match_id\", \"resid\", \"resid_prev\"] + u_prev_cols].dropna(subset=[\"resid_prev\"])\n",
    "\n",
    "# 3) 标准化 u_prev（避免尺度失配导致 sigma 爆炸）；resid 本身在 [-1,1]，无需缩放\n",
    "sc_U = StandardScaler()\n",
    "U_prev_std = sc_U.fit_transform(b[u_prev_cols].values.astype(float))\n",
    "\n",
    "r_t = torch.tensor(b[\"resid\"].values, dtype=torch.float32)\n",
    "r_prev = torch.tensor(b[\"resid_prev\"].values, dtype=torch.float32)\n",
    "U_prev = torch.tensor(U_prev_std, dtype=torch.float32)\n",
    "\n",
    "# 模型：r_t ~ Normal(phi * r_{t-1} + gamma^T u_{t-1}, sigma)\n",
    "def model(r_prev, U_prev, r_t):\n",
    "    phi = pyro.sample(\"phi\", dist.Normal(0.0, 1.0))\n",
    "    gamma = pyro.sample(\"gamma\", dist.Normal(torch.zeros(U_prev.shape[1]), torch.ones(U_prev.shape[1])).to_event(1))\n",
    "    sigma = pyro.sample(\"sigma\", dist.HalfNormal(0.5))  # 更小的先验尺度\n",
    "    mu = phi * r_prev + (U_prev @ gamma)\n",
    "    with pyro.plate(\"data\", len(r_t)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mu, sigma), obs=r_t)\n",
    "\n",
    "# 引导：对 sigma 用 LogNormal 形式更稳定\n",
    "def guide(r_prev, U_prev, r_t):\n",
    "    phi_loc = pyro.param(\"phi_loc\", torch.tensor(0.0))\n",
    "    phi_scale = pyro.param(\"phi_scale\", torch.tensor(0.1), constraint=dist.constraints.positive)\n",
    "    gamma_loc = pyro.param(\"gamma_loc\", torch.zeros(U_prev.shape[1]))\n",
    "    gamma_scale = pyro.param(\"gamma_scale\", torch.ones(U_prev.shape[1]) * 0.1, constraint=dist.constraints.positive)\n",
    "    sigma_loc = pyro.param(\"sigma_loc\", torch.tensor(-1.0))\n",
    "    sigma_scale = pyro.param(\"sigma_scale\", torch.tensor(0.2), constraint=dist.constraints.positive)\n",
    "    pyro.sample(\"phi\", dist.Normal(phi_loc, phi_scale))\n",
    "    pyro.sample(\"gamma\", dist.Normal(gamma_loc, gamma_scale).to_event(1))\n",
    "    pyro.sample(\"sigma\", dist.LogNormal(sigma_loc, sigma_scale))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "optimizer = ClippedAdam({\"lr\": 0.005})\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "for step in range(4000):\n",
    "    loss = svi.step(r_prev, U_prev, r_t)\n",
    "    if step % 500 == 0:\n",
    "        print(f\"step {step}, ELBO: {loss:.4f}\")\n",
    "\n",
    "phi_est = pyro.param(\"phi_loc\").item()\n",
    "gamma_est = pyro.param(\"gamma_loc\").detach().numpy()\n",
    "sigma_med = float(torch.exp(pyro.param(\"sigma_loc\")))  # LogNormal 的中位数\n",
    "print(\"\\n贝叶斯残差参数（均值场近似）：\")\n",
    "print(\"phi        :\", phi_est)\n",
    "print(\"gamma mean :\", gamma_est)\n",
    "print(\"sigma med  :\", sigma_med)\n",
    "\n",
    "# 4) 按比赛分组递推动量 M_t（使用标准化后的 u_prev）\n",
    "phi = float(phi_est)\n",
    "gamma = gamma_est.astype(float)\n",
    "U_std_df = pd.DataFrame(U_prev_std, index=b.index, columns=u_prev_cols)\n",
    "Mt_sub = np.zeros(len(b), dtype=float)\n",
    "pos_map = {idx: i for i, idx in enumerate(b.index)}\n",
    "\n",
    "for mid, g in b.groupby(\"match_id\", sort=False):\n",
    "    idxs = g.index.to_list()\n",
    "    for j, idx_row in enumerate(idxs):\n",
    "        pos = pos_map[idx_row]\n",
    "        if j == 0:\n",
    "            Mt_sub[pos] = 0.0\n",
    "        else:\n",
    "            u_vec = U_std_df.loc[idx_row].values.astype(float)\n",
    "            prev_pos = pos_map[idxs[j - 1]]\n",
    "            Mt_sub[pos] = phi * Mt_sub[prev_pos] + gamma.dot(u_vec)\n",
    "\n",
    "alpha = 1.0\n",
    "p_base_series = pd.Series(proba_all, index=df.index)\n",
    "y_series = pd.Series(y, index=df.index)\n",
    "p_base_sub = p_base_series.loc[b.index].values\n",
    "y_sub = y_series.loc[b.index].values\n",
    "\n",
    "logit_base_sub = np.log(p_base_sub / (1.0 - p_base_sub))\n",
    "logit_adj_sub = logit_base_sub + alpha * Mt_sub\n",
    "p_adj_sub = 1.0 / (1.0 + np.exp(-logit_adj_sub))\n",
    "\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score\n",
    "print(\"\\n评估（基线 vs 贝叶斯动量 logit 修正）\")\n",
    "print(\"Baseline  LogLoss:\", log_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  LogLoss:\", log_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  Brier  :\", brier_score_loss(y_sub, p_base_sub))\n",
    "print(\"Momentum  Brier  :\", brier_score_loss(y_sub, p_adj_sub))\n",
    "print(\"Baseline  ROC AUC:\", roc_auc_score(y_sub, p_base_sub))\n",
    "print(\"Momentum  ROC AUC:\", roc_auc_score(y_sub, p_adj_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c5f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[控制基线] Group 留出评估\n",
      "LogLoss: 0.6380637215205914\n",
      "Brier  : 0.22272501307219322\n",
      "ROC AUC: 0.6684257306235558\n",
      "\n",
      "[控制基线] 残差 ARX 结果\n",
      "RMSE(resid): 0.21880958485917723\n",
      "R^2(resid) : 0.0020291419281776024\n",
      "phi(resid_prev): 0.024958710549519286\n",
      "截距: 0.0014382493822839553\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 11. 实验A：控制基线（无 prev_*） + 残差动量 sanity check\n",
    "# 目的：把短期记忆从 baseline 拿掉，看残差是否更可预测\n",
    "# =========================\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "control_cols = [\n",
    "    \"server\", \"serve_no\",\n",
    "    \"set_no\", \"game_no\", \"point_no\",\n",
    "    \"p1_games\", \"p2_games\", \"p1_sets\", \"p2_sets\",\n",
    "    \"is_break_point\", \"is_tiebreak\", \"is_deuce\",\n",
    " ]\n",
    "\n",
    "X_ctrl = df[control_cols].copy().fillna(0)\n",
    "groups = df[\"match_id\"].values\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X_ctrl, y, groups))\n",
    "\n",
    "Xc_train, Xc_test = X_ctrl.iloc[train_idx], X_ctrl.iloc[test_idx]\n",
    "yc_train, yc_test = y[train_idx], y[test_idx]\n",
    "\n",
    "pipe_ctrl = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=2000))\n",
    "])\n",
    "pipe_ctrl.fit(Xc_train, yc_train)\n",
    "\n",
    "proba_ctrl_test = pipe_ctrl.predict_proba(Xc_test)[:, 1]\n",
    "print(\"\\n[控制基线] Group 留出评估\")\n",
    "print(\"LogLoss:\", log_loss(yc_test, proba_ctrl_test))\n",
    "print(\"Brier  :\", brier_score_loss(yc_test, proba_ctrl_test))\n",
    "print(\"ROC AUC:\", roc_auc_score(yc_test, proba_ctrl_test))\n",
    "\n",
    "# 全量 residual 用于动量检验\n",
    "proba_ctrl_all = pipe_ctrl.predict_proba(X_ctrl)[:, 1]\n",
    "resid_ctrl = y - proba_ctrl_all\n",
    "\n",
    "# 用和之前相同的 u_prev_cols 测试残差是否更可预测\n",
    "df_ctrl = df.copy()\n",
    "df_ctrl[u_prev_cols] = df_ctrl[u_prev_cols].fillna(0)\n",
    "df_ctrl[\"resid_ctrl\"] = resid_ctrl\n",
    "df_ctrl[\"resid_ctrl_prev\"] = df_ctrl.groupby(\"match_id\")[\"resid_ctrl\"].shift(1)\n",
    "\n",
    "df_ctrl_sorted = df_ctrl.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\")\n",
    "arx_ctrl_df = df_ctrl_sorted[[\"resid_ctrl\", \"resid_ctrl_prev\"] + u_prev_cols].dropna()\n",
    "\n",
    "Zc = arx_ctrl_df[[\"resid_ctrl_prev\"] + u_prev_cols].values\n",
    "rc = arx_ctrl_df[\"resid_ctrl\"].values\n",
    "arx_ctrl = LinearRegression()\n",
    "arx_ctrl.fit(Zc, rc)\n",
    "rh = arx_ctrl.predict(Zc)\n",
    "\n",
    "print(\"\\n[控制基线] 残差 ARX 结果\")\n",
    "print(\"RMSE(resid):\", mean_squared_error(rc, rh))\n",
    "print(\"R^2(resid) :\", r2_score(rc, rh))\n",
    "print(\"phi(resid_prev):\", arx_ctrl.coef_[0])\n",
    "print(\"截距:\", arx_ctrl.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[事件驱动动量] 残差 ARX\n",
      "RMSE(resid): 0.2186494894378006\n",
      "R^2(resid) : 0.0024914706544719722\n",
      "phi(resid_prev): 0.0348291134118627\n",
      "Top事件系数：\n",
      "         prev_p2_unf_err : -0.0147\n",
      "    prev_p1_double_fault : +0.0098\n",
      "    prev_p2_double_fault : +0.0078\n",
      "             prev_p2_ace : -0.0075\n",
      "    prev_p2_break_pt_won : +0.0071\n",
      "         prev_p1_unf_err : -0.0065\n",
      "          prev_p2_winner : +0.0051\n",
      "          prev_p1_winner : +0.0044\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 12. 实验B：事件驱动的 u_prev（ace/DF/winner/UE/break miss），检验是否带来更强动量\n",
    "# =========================\n",
    "candidate_events = [\n",
    "    \"p1_ace\", \"p2_ace\",\n",
    "    \"p1_double_fault\", \"p2_double_fault\",\n",
    "    \"p1_winner\", \"p2_winner\",\n",
    "    \"p1_unf_err\", \"p2_unf_err\",\n",
    "    \"p1_break_pt_missed\", \"p2_break_pt_missed\",\n",
    "    \"p1_break_pt_won\", \"p2_break_pt_won\",\n",
    "]\n",
    "\n",
    "event_cols = [c for c in candidate_events if c in df.columns]\n",
    "if not event_cols:\n",
    "    print(\"未找到事件类列，跳过实验B\")\n",
    "else:\n",
    "    df_ev = df.copy()\n",
    "    # 为事件列构造上一分特征\n",
    "    for c in event_cols:\n",
    "        df_ev[f\"prev_{c}\"] = df_ev.groupby(\"match_id\")[c].shift(1)\n",
    "    u_prev_events = [f\"prev_{c}\" for c in event_cols]\n",
    "\n",
    "    df_ev[u_prev_events] = df_ev[u_prev_events].fillna(0)\n",
    "    df_ev[\"resid_base\"] = y - pipe.predict_proba(X)[:, 1]\n",
    "    df_ev[\"resid_base_prev\"] = df_ev.groupby(\"match_id\")[\"resid_base\"].shift(1)\n",
    "\n",
    "    df_ev_sorted = df_ev.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\")\n",
    "    ev_df = df_ev_sorted[[\"match_id\", \"resid_base\", \"resid_base_prev\"] + u_prev_events].dropna(subset=[\"resid_base_prev\"])\n",
    "\n",
    "    # 标准化事件驱动特征\n",
    "    sc_ev = StandardScaler()\n",
    "    Ue = sc_ev.fit_transform(ev_df[u_prev_events].values.astype(float))\n",
    "    re = ev_df[\"resid_base\"].values\n",
    "    re_prev = ev_df[\"resid_base_prev\"].values\n",
    "    Z_evt = np.column_stack([re_prev, Ue])\n",
    "\n",
    "    arx_ev = LinearRegression()\n",
    "    arx_ev.fit(Z_evt, re)\n",
    "    r_hat_ev = arx_ev.predict(Z_evt)\n",
    "\n",
    "    print(\"\\n[事件驱动动量] 残差 ARX\")\n",
    "    print(\"RMSE(resid):\", mean_squared_error(re, r_hat_ev))\n",
    "    print(\"R^2(resid) :\", r2_score(re, r_hat_ev))\n",
    "    print(\"phi(resid_prev):\", arx_ev.coef_[0])\n",
    "    # 输出最重要的事件驱动系数\n",
    "    gamma_ev = arx_ev.coef_[1:]\n",
    "    topk = min(8, len(u_prev_events))\n",
    "    idx_sorted = np.argsort(-np.abs(gamma_ev))[:topk]\n",
    "    print(\"Top事件系数：\")\n",
    "    for i in idx_sorted:\n",
    "        print(f\"{u_prev_events[i]:>24} : {gamma_ev[i]:+0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d34e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200/200 ELBO per-pt: 0.6552"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "## 13. DBN：控制基线 + 标量动量 M_t（logit 空间联合训练，整批训练避免先验重复）\n",
    "## - 约束 rho ∈ (-1,1) 用 tanh\n",
    "## - ctrl / u 均标准化以匹配先验尺度\n",
    "## - 可在后续用 match 留出做严格评估\n",
    "# =========================\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import ClippedAdam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Install pyro-ppl if not already installed\n",
    "try:\n",
    "    import pyro\n",
    "except ImportError:\n",
    "    !pip install pyro-ppl\n",
    "    import pyro\n",
    "\n",
    "# Detect device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 控制变量（弱化 baseline）\n",
    "ctrl_cols = [\n",
    "    \"server\", \"serve_no\",\n",
    "    \"set_no\", \"game_no\", \"point_no\",\n",
    "    \"p1_games\", \"p2_games\", \"p1_sets\", \"p2_sets\",\n",
    "    \"is_break_point\", \"is_tiebreak\", \"is_deuce\",\n",
    "]\n",
    "\n",
    "# 事件驱动 + 体能/发球状态驱动（上一分/窗口）\n",
    "event_cols = [c for c in [\n",
    "    \"p1_ace\", \"p2_ace\",\n",
    "    \"p1_double_fault\", \"p2_double_fault\",\n",
    "    \"p1_winner\", \"p2_winner\",\n",
    "    \"p1_unf_err\", \"p2_unf_err\",\n",
    "    \"p1_break_pt_missed\", \"p2_break_pt_missed\",\n",
    "    \"p1_break_pt_won\", \"p2_break_pt_won\",\n",
    "] if c in df.columns]\n",
    "\n",
    "df_m = df.sort_values([\"match_id\", \"set_no\", \"game_no\", \"point_no\", \"elapsed_seconds\"], kind=\"mergesort\").copy()\n",
    "\n",
    "# 构造上一分事件特征\n",
    "for c in event_cols:\n",
    "    df_m[f\"prev_{c}\"] = df_m.groupby(\"match_id\")[c].shift(1)\n",
    "\n",
    "# 构造简单 EWMA（疲劳/发球状态），并 shift(1) 防泄漏\n",
    "def ewm_prev(series, span=5):\n",
    "    return series.shift(1).ewm(span=span, adjust=False).mean()\n",
    "\n",
    "df_m[\"rally_ewm\"] = df_m.groupby(\"match_id\")[\"rally_count\"].transform(lambda s: ewm_prev(s, span=6))\n",
    "df_m[\"dist_ewm\"] = df_m.groupby(\"match_id\")[\"p1_distance_run\"].transform(lambda s: ewm_prev(s, span=6))\n",
    "df_m[\"serve_speed_ewm\"] = df_m.groupby(\"match_id\")[\"speed_mph\"].transform(lambda s: ewm_prev(s, span=6))\n",
    "\n",
    "u_cols = []\n",
    "u_cols += [f\"prev_{c}\" for c in event_cols]\n",
    "u_cols += [\"rally_ewm\", \"dist_ewm\", \"serve_speed_ewm\"]\n",
    "\n",
    "df_m[u_cols] = df_m[u_cols].fillna(0)\n",
    "\n",
    "# 设计矩阵（ctrl 也做标准化，避免尺度失配导致先验过度收缩）\n",
    "X_ctrl_raw = df_m[ctrl_cols].fillna(0).values\n",
    "sc_ctrl = StandardScaler()\n",
    "X_ctrl = sc_ctrl.fit_transform(X_ctrl_raw)\n",
    "\n",
    "U_drv = df_m[u_cols].values\n",
    "sc_u = StandardScaler()\n",
    "U_std = sc_u.fit_transform(U_drv)\n",
    "\n",
    "y_arr = df_m[\"y\"].values.astype(float)\n",
    "\n",
    "# match_id 编码为整数\n",
    "match_codes, match_uniques = pd.factorize(df_m[\"match_id\"], sort=False)\n",
    "\n",
    "ctrl_tensor = torch.tensor(X_ctrl, dtype=torch.float32).to(device)\n",
    "u_tensor = torch.tensor(U_std, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y_arr, dtype=torch.float32).to(device)\n",
    "match_tensor = torch.tensor(match_codes, dtype=torch.long).to(device)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "def dbn_model(ctrl, u, match_ids, y):\n",
    "    T, p = ctrl.shape\n",
    "    q = u.shape[1]\n",
    "    beta = pyro.sample(\"beta\", dist.Normal(0.0, 1.0).expand([p]).to_event(1)).to(device)\n",
    "    rho_raw = pyro.sample(\"rho_raw\", dist.Normal(0.0, 1.0)).to(device)\n",
    "    rho = torch.tanh(rho_raw)\n",
    "    eta = pyro.sample(\"eta\", dist.Normal(0.0, 1.0).expand([q]).to_event(1)).to(device)\n",
    "    logits = []\n",
    "    M_prev = torch.tensor(0.0, device=device)\n",
    "    last_mid = match_ids[0] if T > 0 else torch.tensor(-1, device=device)\n",
    "    for t in range(T):\n",
    "        if match_ids[t] != last_mid:\n",
    "            M_prev = torch.tensor(0.0, device=device)\n",
    "            last_mid = match_ids[t]\n",
    "        mean_M = rho * M_prev + (u[t] @ eta)\n",
    "        M_prev = mean_M\n",
    "        logit_t = (ctrl[t] @ beta) + M_prev\n",
    "        pyro.sample(f\"y_{t}\", dist.Bernoulli(logits=logit_t), obs=y[t])\n",
    "        logits.append(logit_t)\n",
    "    return torch.stack(logits) if logits else torch.tensor([], device=device)\n",
    "\n",
    "guide = pyro.infer.autoguide.AutoNormal(dbn_model)\n",
    "optimizer = ClippedAdam({\"lr\": 0.003})\n",
    "svi = SVI(dbn_model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# 整批训练，避免先验在 mini-batch 下被重复放大\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    loss = svi.step(ctrl_tensor, u_tensor, match_tensor, y_tensor)\n",
    "    print(f\"\\repoch {epoch+1}/{n_epochs} ELBO per-pt: {loss/len(df_m):.4f}\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c0b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DBN 动量] 全量评估 (提醒：当前未做 match 留出)\n",
      "LogLoss: 0.6324973369785187\n",
      "Brier  : 0.2203022688627243\n",
      "ROC AUC: 0.6881189855056287\n",
      "\n",
      "动量 M_t 概要（确定性均值递推）：\n",
      "count    7284.000000\n",
      "mean        0.000549\n",
      "std         0.137156\n",
      "min        -0.648622\n",
      "25%        -0.102190\n",
      "50%         0.028821\n",
      "75%         0.058438\n",
      "max         0.496915\n",
      "Name: Mt_mean, dtype: float64\n",
      "提示：如需严格评估，请先按 match_id 过滤训练/验证，再各自跑一遍 SVI 与预测。\n"
     ]
    }
   ],
   "source": [
    "# 取 posterior 平均的 logits 进行评估（仅取 _RETURN 以避免内存爆）\n",
    "from pyro.distributions import constraints\n",
    "from pyro.distributions.transforms import biject_to\n",
    "\n",
    "predictive = Predictive(dbn_model, guide=guide, num_samples=20, return_sites=[\"_RETURN\"])\n",
    "samples = predictive(ctrl_tensor, u_tensor, match_tensor, y_tensor)\n",
    "logits_mc = samples[\"_RETURN\"]  # [S, T]\n",
    "p_mc = torch.sigmoid(logits_mc)\n",
    "p_mean = p_mc.mean(0).detach().cpu().numpy()\n",
    "y_np = y_tensor.cpu().numpy()\n",
    "\n",
    "print(\"\\n[DBN 动量] 全量评估 (提醒：当前未做 match 留出)\")\n",
    "print(\"LogLoss:\", log_loss(y_np, p_mean))\n",
    "print(\"Brier  :\", brier_score_loss(y_np, p_mean))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_np, p_mean))\n",
    "\n",
    "# 用后验均值参数递推一个确定性的 M_t 均值，避免逐点采样导致内存溢出\n",
    "rho_raw_loc = pyro.param(\"AutoNormal.locs.rho_raw\")\n",
    "rho = float(torch.tanh(rho_raw_loc))\n",
    "eta = biject_to(constraints.real)(pyro.param(\"AutoNormal.locs.eta\")).detach().cpu().numpy()\n",
    "Mt_det = np.zeros(len(df_m), dtype=float)\n",
    "last_mid = match_codes[0] if len(match_codes) > 0 else -1\n",
    "\n",
    "for i in range(len(df_m)):\n",
    "    if match_codes[i] != last_mid:\n",
    "        Mt_det[i] = 0.0\n",
    "        last_mid = match_codes[i]\n",
    "    else:\n",
    "        Mt_det[i] = rho * Mt_det[i-1] + eta.dot(U_std[i])\n",
    "\n",
    "df_m[\"Mt_mean\"] = Mt_det\n",
    "print(\"\\n动量 M_t 概要（确定性均值递推）：\")\n",
    "print(df_m[\"Mt_mean\"].describe())\n",
    "print(\"提示：如需严格评估，请先按 match_id 过滤训练/验证，再各自跑一遍 SVI 与预测。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
